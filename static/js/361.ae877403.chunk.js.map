{"version":3,"file":"static/js/361.ae877403.chunk.js","mappings":"2HAkBA,IAhBuB,SAAC,GAA6B,IAA3BA,EAA0B,EAA1BA,MAAOC,EAAmB,EAAnBA,QAASC,EAAU,EAAVA,IAKxC,YAJYC,IAARD,IACFA,EAAMD,IAIF,iBAAKG,UAAW,oBAAhB,WACI,gBAAKC,IAAKL,EAAOI,UAAS,qFACZD,IAAZF,EAAwB,mBAAqB,IAAMC,IAAKA,KAC1D,gBAAKE,UAAU,oBAAf,UACI,cAAGA,UAAW,8CAAd,SAA8DH,W,yJCkB9E,EAxBMK,SAAAA,IAAAA,EAAAA,EAAAA,GAAAA,EAAAA,GAAAA,IAAAA,GAAAA,EAAAA,EAAAA,GAAAA,GACJ,WAAaC,GAAQ,IAAD,yBAClB,cAAMA,IACDC,KAAOD,EAAMC,KAClB,EAAKC,SAAWF,EAAME,SAHJ,EAoBnB,OAhBA,yCAED,WACEC,IAAAA,iBACD,oBAED,WACE,OACQ,gBAAKN,UAAU,aAAf,UACI,gBAAKA,UAAW,yCAAhB,UACI,iBAAMA,UAAS,mBAAcO,KAAKF,UAAlC,SACKE,KAAKH,eAK3B,EArBGF,CAAoBM,EAAAA,Y,4aC6DpBC,EAAqB,qXAE3B,EAzDoB,WAClB,OACM,iCACA,sDACA,oCAAU,cAAGC,KAAK,sBAAR,oBAAV,wSAMA,iBAAKV,UAAU,sCAAf,WACE,SAACW,EAAA,EAAD,CAAgBf,MAAOgB,EAAiBf,QAAQ,sBAChD,SAACc,EAAA,EAAD,CAAgBf,MAAOiB,EAAahB,QAAQ,qBAE9C,mBACA,+DAAqC,cAAGa,KAAK,mEAAR,2BAArC,sHACmE,cAAGA,KAAK,4DAAR,kCADnE,kPAKA,iBAAKV,UAAU,sCAAf,WACE,SAACW,EAAA,EAAD,CAAgBf,M,isWAAqBC,QAAQ,+CAC7C,SAACc,EAAA,EAAD,CAAgBf,MAAOkB,EAAejB,QAAQ,yBAC9C,SAACc,EAAA,EAAD,CAAgBf,MAAOmB,EAAkBlB,QAAQ,sCAEnD,mBACA,qHAA2F,cAAGa,KAAK,sCAAR,uBAA3F,sMAIA,mBACA,SAACR,EAAA,EAAD,CAAaG,SAAS,SAAQD,KAAMK,KAEpC,kCAAQ,cAAGC,KAAK,4CAAR,yBAAR,4TAKA,SAACC,EAAA,EAAD,CAAgBf,MAAOoB,EAAenB,QAAQ,8CAE9C,mBACA,gDACA,8GAAoF,cAAGa,KAAK,qDAAR,uBAApF,2UAIO,cAAGA,KAAK,wDAAR,mBAJP,oT","sources":["components/CaptionedImage/CaptionedImage.js","components/CodeSnippet/CodeSnippet.js","pages/projects/3dPrintErrorDetection.js"],"sourcesContent":["import React from 'react'\n\nconst CaptionedImage = ({ image, caption, alt }) => {\n  if (alt === undefined) {\n    alt = caption\n  }\n\n  return (\n        <div className={'flex flex-col m-2'}>\n            <img src={image} className={`max-w-80 max-h-80 border-amber-500 rounded-md border-b-2\n            ${caption !== undefined ? ' rounded-bl-none' : ''}`} alt={alt}></img>\n            <div className=\"flex rounded-b-lg\">\n                <p className={'mt-0 px-1 text-sm bg-amber-500 rounded-b-sm'}>{caption}</p>\n            </div>\n        </div>\n  )\n}\n\nexport default CaptionedImage\n","import React from 'react'\nimport Prism from 'prismjs'\nimport './prismDark.css'\nimport 'prismjs/components/prism-python'\nimport 'prismjs/components/prism-c'\n\nclass CodeSnippet extends React.Component {\n  constructor (props) {\n    super(props)\n    this.code = props.code\n    this.language = props.language\n  }\n\n  componentDidMount () {\n    Prism.highlightAll()\n  }\n\n  render () {\n    return (\n            <div className=\"max-w-full\">\n                <pre className={'rounded-md border-amber-500 border-b-2'}>\n                    <code className={`language-${this.language}`}>\n                        {this.code}\n                    </code>\n                </pre>\n            </div>\n    )\n  }\n};\n\nexport default CodeSnippet\n","import React from 'react'\nimport '../Pages.css'\nimport CaptionedImage from '../../components/CaptionedImage/CaptionedImage'\n\nimport successfulPrint from '../../images/successfulCube.jpg'\nimport failedPrint from '../../images/failedCube.jpg'\nimport cannyExample from '../../images/cannyExampleImage.png'\nimport imageContours from '../../images/imageContours.png'\nimport filteredContours from '../../images/filteredContours.png'\nimport outlinedPrint from '../../images/successfulPrintWithOutline.png'\nimport CodeSnippet from '../../components/CodeSnippet/CodeSnippet'\n\nconst ThisWebsite = () => {\n  return (\n        <>\n        <h1>3D Print Error Detection</h1>\n        <p>I used <a href=\"https://opencv.org/\">OpenCV</a> to identify when a 3D print fails.\n            This is accomplished by digitally projecting the model onto print bed,\n            then comparing the identified print with the expected projection. The program\n            takes in an image stream of the 3D printer and the original stl file to determine \n            when a failure occurs.</p>\n          \n        <div className='flex flex-wrap gap-8 justify-center'>\n          <CaptionedImage image={successfulPrint} caption='Successful Print'/>\n          <CaptionedImage image={failedPrint} caption='Failed Print'/>\n        </div>\n        <br></br>\n        <p>The program starts by identifying <a href=\"https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html\">ArUco markers</a> that are placed on the corner of the print bed.\n          This establish the scale, position and orientation of the image. <a href=\"https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html\">Canny Edge Detection</a> is applied to \n          the image to identify the outlines of image features. Next, OpenCV's findContours() function is used\n          to isolate the contiguous shapes in the image. The contour in the location of the bed's center is saved for comparison.</p>\n        \n        <div className='flex flex-wrap gap-8 justify-center'>\n          <CaptionedImage image={cannyExample} caption='Image after applying Canny Edge Detection'/>\n          <CaptionedImage image={imageContours} caption='Identified contours'/>\n          <CaptionedImage image={filteredContours} caption='Contours filtered by location'/>\n        </div>\n        <br></br>\n        <p>To know what shape should be expected, points are extracted from the stl file using the <a href=\"https://github.com/WoLpH/numpy-stl/\">numpy-stl</a> Python library. \n        The homography identified from the ArUco markers is used to transform of these 3D\n        points onto a 2D plane with the correct perspective using the following transformation code.</p>\n          \n        <br></br>\n        <CodeSnippet language=\"python\"code={transformationCode}/>\n\n        <p> The <a href=\"https://en.wikipedia.org/wiki/Graham_scan\">Graham Scan</a> convex hull algorithm is then used to identify the outline that \n          should be expected. OpenCV's matchShapes() function is used to compare this calculated outline contour\n          with the print contour that was found in the image. If the contours match within \n          an acceptable threshold, the print is labeled as successful.\n        </p>\n        <CaptionedImage image={outlinedPrint} caption='Image labeled with expected edge contour'/>\n        \n        <br></br>\n        <h2>Discussion and Use</h2>\n        <p>To be used, this program would be coordinated with a print imaging software like <a href=\"\\https://plugins.octoprint.org/plugins/octolapse/\">Octolapse</a> to\n          move the printhead out of the way after each layer so that a clear image can be taken. To accommodate these intermediate steps,\n          the points from the stl file would be interpolated, then filtered by z height. Notifications could be sent\n          or the print could be paused if an issue was detected. In practice, an AI approach \n          like <a href=\"https://github.com/TheSpaghettiDetective/obico-server\">Obico</a> would be more practical for general printing because \n          it it does not require the use of ArUco markers. However, this computer vision\n          approach is useful for verifying dimensions and quality since it can detect small variation from the original\n          3D model - even if the print is not completely ruined.\n        </p>\n        </>\n  )\n}\n\nconst transformationCode = \"# Create the transformation matrix\\nR, _ = cv2.Rodrigues(rvec)\\nex = np.block([R, tvec.T])\\ntransformation = np.block([transformation, 1])\\n\\n# Apply the transformation matrix to a point\\npoint = K @ ex @ transformation\\n\\n# normalize the coordinates with respect to the z-axis\\npoint = np.divide(point, point[2])\\n\\n# Report the new (x, y) coordinates\\nreturn point[:2]\"\n\nexport default ThisWebsite\n"],"names":["image","caption","alt","undefined","className","src","CodeSnippet","props","code","language","Prism","this","React","transformationCode","href","CaptionedImage","successfulPrint","failedPrint","imageContours","filteredContours","outlinedPrint"],"sourceRoot":""}