{"version":3,"file":"static/js/65.20669173.chunk.js","mappings":"0HAkBA,IAhBuB,SAAC,GAA6B,IAA3BA,EAA0B,EAA1BA,MAAOC,EAAmB,EAAnBA,QAASC,EAAU,EAAVA,IAKxC,YAJYC,IAARD,IACFA,EAAMD,IAIF,iBAAKG,UAAW,oBAAhB,WACI,gBAAKC,IAAKL,EAAOI,UAAS,qFACZD,IAAZF,EAAwB,mBAAqB,IAAMC,IAAKA,KAC1D,gBAAKE,UAAU,oBAAf,UACI,cAAGA,UAAW,8CAAd,SAA8DH,W,+rBCuF9E,EArFuB,WACrB,OACM,iCACA,mEACA,6LAC0E,cAAGK,KAAK,2BAAR,qBAD1E,qQAMA,iBAAKF,UAAU,sCAAf,WACE,SAACG,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOS,EAAcR,QAAQ,0CAC5D,SAACM,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOU,EAAaT,QAAQ,0CAE7D,gLAEA,mBAGA,6CACA,saAKA,SAACM,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOW,EAAoBV,QAAQ,yBAElE,4BACA,6EACA,2BACE,qCAAM,cAAGK,KAAK,0BAAR,wBACN,qCAAM,cAAGA,KAAK,uBAAR,sBACN,qCAAM,cAAGA,KAAK,sBAAR,wBACN,qCAAM,cAAGA,KAAK,4BAAR,oCAGR,mBAEA,6CACA,kaAKA,iBAAKF,UAAU,sCAAf,WACE,SAACG,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOY,EAAcX,QAAQ,gCAC5D,SAACM,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOa,EAAkBZ,QAAQ,kCAElE,mBACA,mCAAS,cAAGK,KAAK,0EAAR,+BAAT,+HAEA,SAACC,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOc,EAAkBb,QAAQ,iCAEhE,2bAMA,iBAAKG,UAAU,sCAAf,WACE,SAACG,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOe,EAAkBd,QAAQ,2BAChE,SAACM,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOgB,EAAuBf,QAAQ,wCAEvE,qLAGA,SAACM,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOiB,EAAiBhB,QAAQ,yCAE/D,mBAEA,8CACA,4IACM,cAAGK,KAAK,qCAAR,kBADN,yFAGA,SAACC,EAAA,EAAD,CAAgBC,UAAW,GAAIR,MAAOkB,EAAsBjB,QAAQ,2CACpE,mBAEA,wDACA,cAAGK,KAAK,gDAAR,gE","sources":["components/CaptionedImage/CaptionedImage.js","pages/projects/humanDetection.js"],"sourcesContent":["import React from 'react'\n\nconst CaptionedImage = ({ image, caption, alt }) => {\n  if (alt === undefined) {\n    alt = caption\n  }\n\n  return (\n        <div className={'flex flex-col m-2'}>\n            <img src={image} className={`max-w-80 max-h-80 border-amber-500 rounded-md border-b-2\n            ${caption !== undefined ? ' rounded-bl-none' : ''}`} alt={alt}></img>\n            <div className=\"flex rounded-b-lg\">\n                <p className={'mt-0 px-1 text-sm bg-amber-500 rounded-b-sm'}>{caption}</p>\n            </div>\n        </div>\n  )\n}\n\nexport default CaptionedImage\n","import React from 'react'\nimport '../Pages.css'\nimport CaptionedImage from '../../components/CaptionedImage/CaptionedImage'\nimport refuelingArm from '../../images/refuelingArm.jpg'\nimport systemArchitecture from '../../images/humanDetectionSystemArchitecture.png'\nimport humanDetectionCamera from '../../images/humanDetectionCamera.png'\nimport probabilityCloud from '../../images/probabilityCloud.png'\nimport rawLidarData from '../../images/rawLidarData.png'\nimport cleanedLidarData from '../../images/cleanedLidarData.png'\nimport clusterLidarData from '../../images/clusteredLidarData.png'\nimport humanClusterLidarData from '../../images/humanClusterLidarData.png'\nimport finalResult from '../../images/finalProductStratom.jpg'\nimport identifiedHuman from '../../images/identifiedHuman.png'\n\nconst HumanDetection = () => {\n  return (\n        <>\n        <h1>Human Detection using LIDAR and Video</h1>\n        <p>For my senior capstone project, I worked with a team of 3 other engineering students to\n          develop a reliable system of human detection for the automation company <a href=\"https://www.stratom.com/\">Stratom</a>.\n          The project uses live camera and LIDAR data to help Stratom's automated systems avoid human collisions. For example,\n          the project could be implemented on the autonomous refueling arm shown below so that it would pause operation if a \n          human got too close. \n        </p>\n        <div className='flex flex-wrap gap-8 justify-center'>\n          <CaptionedImage maxHeight={72} image={refuelingArm} caption=\"RAPID™ Autonomous Refueling Arm\"/>\n          <CaptionedImage maxHeight={72} image={finalResult} caption=\"Live demo of human identification\"/>\n        </div>\n        <p>My primary technical role in this project was the creation of the Docker environment and the development and \n          implementation of the LIDAR detection.</p>\n        <br></br>\n\n\n        <h2>System Overview</h2>\n        <p> Video, LIDAR and position data are consumed and processed to produce a final location and confidence \n          interval for each identified human. Additionally, camera and LIDAR images are annotated and published with the \n          detected locations. The program is encapsulated inside of a Docker container so that it can be easily run on any system. \n          It is comprised of ROS nodes as shown in the diagram below.\n        </p>\n        <CaptionedImage maxHeight={72} image={systemArchitecture} caption=\"System Architecture\"/>\n\n        <div>\n        <p>The project utilizes the following technologies:</p>\n        <ul>\n          <li>• <a href=\"https://www.docker.com/\">Docker</a></li>\n          <li>• <a href=\"https://www.ros.org/\">ROS2</a></li>\n          <li>• <a href=\"https://opencv.org/\">OpenCV</a></li>\n          <li>• <a href=\"https://scikit-learn.org/\">SciKit-Learn</a></li>\n        </ul>\n        </div>\n        <br></br>\n\n        <h2>LIDAR Detection</h2>\n        <p>The LIDAR data is made up of a point cloud created by a series of circular scans from the sensor.\n          The original point cloud data is cleaned to focus in on the important part of the the scan and reduce processing time. \n          Statistical analysis is preformed identify and remove outlier points. Robot position information is used to crop out the floor\n          and area outside of the relevant image frame.\n        </p>\n        <div className='flex flex-wrap gap-8 justify-center'>\n          <CaptionedImage maxHeight={72} image={rawLidarData} caption=\"Original LIDAR point cloud\"/>\n          <CaptionedImage maxHeight={72} image={cleanedLidarData} caption=\"Cleaned LIDAR point cloud\"/>\n        </div>\n        <br></br>\n        <p>Next, <a href=\"https://towardsdatascience.com/dbscan-clustering-explained-97556a2ad556\">DBSCAN Clustering</a> is\n        used to identify discrete objects in the frame. This isolates individual objects in the frame for future processing.</p>\n        <CaptionedImage maxHeight={72} image={clusterLidarData} caption=\"Clustered LIDAR point cloud\"/>\n\n        <p>Each of these clusters are filtered based on size to isolate objects that are approximated human-sized. Next, each cluster\n          is compared to a probability map of expected points for a scan of a human. This probability map was\n          created by normalizing, then averaging a known set of human point cloud clusters. A confidence score is created\n          by summing the difference between a normalized cluster and the probability map.\n          \n        </p>\n        <div className='flex flex-wrap gap-8 justify-center'>\n          <CaptionedImage maxHeight={72} image={probabilityCloud} caption=\"Human probability map\"/>\n          <CaptionedImage maxHeight={72} image={humanClusterLidarData} caption=\"Clusters after applying filters\"/>\n        </div>\n        <p>During testing, this approach was successful about 80% of the time, but excelled in situations with difficult lighting\n          where a camera would have failed.\n        </p>\n        <CaptionedImage maxHeight={72} image={identifiedHuman} caption=\"Final bounding box LIDAR annotation\"/>\n\n        <br></br>\n\n        <h2>Camera Detection</h2>\n        <p>The programs identifies humans from a video stream using a pre-trained neural network call You Only Look \n        Once (<a href=\"https://pjreddie.com/darknet/yolo/\">YOLO</a>). In our testing, the neural network correctly \n        identified humans 85% of the time.</p>\n        <CaptionedImage maxHeight={72} image={humanDetectionCamera} caption=\"Bounding boxes around detected humans\"/>\n        <br></br>\n\n        <p>View the full project here:</p>\n        <a href=\"https://github.com/EthanCranston/StratoMiners\">\n        https://github.com/EthanCranston/StratoMiners</a>\n        \n        </>\n  )\n}\n\nexport default HumanDetection\n"],"names":["image","caption","alt","undefined","className","src","href","CaptionedImage","maxHeight","refuelingArm","finalResult","systemArchitecture","rawLidarData","cleanedLidarData","clusterLidarData","probabilityCloud","humanClusterLidarData","identifiedHuman","humanDetectionCamera"],"sourceRoot":""}